"""
VietShare Article Crawler & AI Rewriter Tool
Tá»± Ä‘á»™ng crawl bÃ i viáº¿t tá»« RSS, dÃ¹ng AI rewrite, vÃ  Ä‘Äƒng lÃªn Firebase
"""

import json
import os
import re
import time
import hashlib
import feedparser
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import google.generativeai as genai

# Load config
CONFIG_FILE = os.path.join(os.path.dirname(__file__), 'config.json')
PROCESSED_FILE = os.path.join(os.path.dirname(__file__), 'processed.json')

def load_config():
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_processed():
    if os.path.exists(PROCESSED_FILE):
        with open(PROCESSED_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_processed(processed):
    with open(PROCESSED_FILE, 'w', encoding='utf-8') as f:
        json.dump(processed, f, ensure_ascii=False, indent=2)

def get_article_hash(url):
    return hashlib.md5(url.encode()).hexdigest()

def fetch_full_content(url):
    """Láº¥y ná»™i dung Ä‘áº§y Ä‘á»§ tá»« URL bÃ i viáº¿t"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # TÃ¬m ná»™i dung chÃ­nh (cÃ¡c selector phá»• biáº¿n)
        content_selectors = [
            'article', '.article-content', '.content-detail', 
            '.fck_detail', '.the-article-body', '.post-content',
            '#content', '.entry-content'
        ]
        
        content = None
        for selector in content_selectors:
            content = soup.select_one(selector)
            if content:
                break
        
        if not content:
            content = soup.find('body')
        
        # Láº¥y text vÃ  lÃ m sáº¡ch
        paragraphs = content.find_all('p')
        text_content = '\n\n'.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])
        
        # Láº¥y áº£nh
        images = []
        for img in content.find_all('img'):
            src = img.get('src') or img.get('data-src')
            if src and not 'logo' in src.lower() and not 'icon' in src.lower():
                if not src.startswith('http'):
                    src = 'https:' + src if src.startswith('//') else src
                images.append(src)
        
        return text_content, images[:5]  # Max 5 áº£nh
        
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return None, []

def rewrite_with_ai(title, content, config, retry_count=0):
    """DÃ¹ng Gemini AI Ä‘á»ƒ viáº¿t láº¡i tiÃªu Ä‘á» vÃ  ná»™i dung"""
    models = ['gemini-2.0-flash', 'gemini-1.5-flash-latest', 'gemini-1.5-pro-latest']
    
    for model_name in models:
        try:
            genai.configure(api_key=config['gemini_api_key'])
            model = genai.GenerativeModel(model_name)
            
            prompt = f"""Báº¡n lÃ  má»™t nhÃ  bÃ¡o cÃ´ng nghá»‡ chuyÃªn nghiá»‡p. HÃ£y viáº¿t láº¡i bÃ i viáº¿t sau thÃ nh má»™t bÃ i viáº¿t Má»šI HOÃ€N TOÃ€N, KHÃC 100% vá» cÃ¢u tá»« nhÆ°ng giá»¯ nguyÃªn Ã½ chÃ­nh.

TIÃŠU Äá»€ Gá»C: {title}

Ná»˜I DUNG Gá»C:
{content[:3000]}

YÃŠU Cáº¦U:
1. Viáº¿t tiÃªu Ä‘á» Má»šI háº¥p dáº«n, SEO-friendly, khÃ¡c hoÃ n toÃ n tiÃªu Ä‘á» gá»‘c
2. Viáº¿t láº¡i ná»™i dung vá»›i giá»ng vÄƒn tá»± nhiÃªn, dá»… Ä‘á»c
3. Giá»¯ cÃ¡c thÃ´ng tin quan trá»ng nhÆ°ng KHÃ”NG copy nguyÃªn vÄƒn
4. ThÃªm cÃ¡c heading h2, h3 phÃ¹ há»£p
5. Äá»™ dÃ i tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c dÃ i hÆ¡n bÃ i gá»‘c
6. Format HTML cho ná»™i dung (dÃ¹ng <p>, <h2>, <h3>, <ul>, <li>)

TRáº¢ Vá»€ ÄÃšNG FORMAT JSON:
{{
  "title": "tiÃªu Ä‘á» má»›i",
  "excerpt": "tÃ³m táº¯t ngáº¯n 1-2 cÃ¢u", 
  "content": "ná»™i dung HTML Ä‘áº§y Ä‘á»§",
  "tags": ["tag1", "tag2", "tag3"]
}}
"""
            
            response = model.generate_content(prompt)
            response_text = response.text
            
            # Parse JSON tá»« response
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                result = json.loads(json_match.group())
                print(f"    ğŸ¤– DÃ¹ng model: {model_name}")
                return result
            
        except Exception as e:
            error_str = str(e)
            if '429' in error_str or 'quota' in error_str.lower():
                print(f"    â³ Rate limit vá»›i {model_name}, thá»­ model khÃ¡c...")
                time.sleep(5)
                continue
            else:
                print(f"    âŒ Lá»—i {model_name}: {e}")
                continue
    
    # Náº¿u táº¥t cáº£ model Ä‘á»u fail, Ä‘á»£i vÃ  retry
    if retry_count < 2:
        print(f"    â³ Äá»£i 60s rá»“i thá»­ láº¡i...")
        time.sleep(60)
        return rewrite_with_ai(title, content, config, retry_count + 1)
    
    return None


def generate_image_prompt(title, content):
    """Táº¡o prompt Ä‘á»ƒ generate áº£nh tá»« ná»™i dung bÃ i"""
    prompt = f"""Create a modern, professional blog thumbnail image for this article:
Title: {title}
Topic: Technology/Tips
Style: Clean, minimalist, tech-focused, vibrant colors, no text in image
"""
    return prompt

def create_slug(title):
    """Táº¡o slug tá»« tiÃªu Ä‘á»"""
    # Bá» dáº¥u tiáº¿ng Viá»‡t
    replacements = {
        'Ã ': 'a', 'Ã¡': 'a', 'áº¡': 'a', 'áº£': 'a', 'Ã£': 'a',
        'Ã¢': 'a', 'áº§': 'a', 'áº¥': 'a', 'áº­': 'a', 'áº©': 'a', 'áº«': 'a',
        'Äƒ': 'a', 'áº±': 'a', 'áº¯': 'a', 'áº·': 'a', 'áº³': 'a', 'áºµ': 'a',
        'Ã¨': 'e', 'Ã©': 'e', 'áº¹': 'e', 'áº»': 'e', 'áº½': 'e',
        'Ãª': 'e', 'á»': 'e', 'áº¿': 'e', 'á»‡': 'e', 'á»ƒ': 'e', 'á»…': 'e',
        'Ã¬': 'i', 'Ã­': 'i', 'á»‹': 'i', 'á»‰': 'i', 'Ä©': 'i',
        'Ã²': 'o', 'Ã³': 'o', 'á»': 'o', 'á»': 'o', 'Ãµ': 'o',
        'Ã´': 'o', 'á»“': 'o', 'á»‘': 'o', 'á»™': 'o', 'á»•': 'o', 'á»—': 'o',
        'Æ¡': 'o', 'á»': 'o', 'á»›': 'o', 'á»£': 'o', 'á»Ÿ': 'o', 'á»¡': 'o',
        'Ã¹': 'u', 'Ãº': 'u', 'á»¥': 'u', 'á»§': 'u', 'Å©': 'u',
        'Æ°': 'u', 'á»«': 'u', 'á»©': 'u', 'á»±': 'u', 'á»­': 'u', 'á»¯': 'u',
        'á»³': 'y', 'Ã½': 'y', 'á»µ': 'y', 'á»·': 'y', 'á»¹': 'y',
        'Ä‘': 'd', 'Ä': 'd'
    }
    
    slug = title.lower()
    for vn, en in replacements.items():
        slug = slug.replace(vn, en)
    
    slug = re.sub(r'[^a-z0-9\s-]', '', slug)
    slug = re.sub(r'[\s_]+', '-', slug)
    slug = re.sub(r'-+', '-', slug)
    slug = slug.strip('-')
    
    return slug[:100]

def process_rss_feed(source, config, processed):
    """Xá»­ lÃ½ má»™t RSS feed"""
    print(f"\nğŸ“¡ Äang crawl: {source['name']}")
    
    try:
        feed = feedparser.parse(source['rss'])
        new_articles = []
        
        for entry in feed.entries[:config['settings']['max_articles_per_run']]:
            article_hash = get_article_hash(entry.link)
            
            if article_hash in processed:
                continue
            
            print(f"  ğŸ“° Äang xá»­ lÃ½: {entry.title[:50]}...")
            
            # Láº¥y ná»™i dung Ä‘áº§y Ä‘á»§
            content, images = fetch_full_content(entry.link)
            
            if not content or len(content) < 200:
                print(f"    âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c ná»™i dung")
                continue
            
            # AI rewrite
            rewritten = rewrite_with_ai(entry.title, content, config)
            
            if not rewritten:
                print(f"    âš ï¸ AI rewrite tháº¥t báº¡i")
                continue
            
            # Táº¡o article object
            article = {
                'title': rewritten['title'],
                'slug': create_slug(rewritten['title']),
                'excerpt': rewritten.get('excerpt', ''),
                'content': rewritten['content'],
                'category': source['category'],
                'tags': rewritten.get('tags', []),
                'thumbnail': images[0] if images else '',
                'original_images': images,
                'source_url': entry.link,
                'source_name': source['name'],
                'publishedAt': datetime.now().isoformat(),
                'views': 0,
                'status': 'published' if config['settings']['auto_publish'] else 'draft'
            }
            
            new_articles.append(article)
            processed.append(article_hash)
            
            print(f"    âœ… ÄÃ£ rewrite: {rewritten['title'][:50]}...")
            
            # Delay Ä‘á»ƒ trÃ¡nh rate limit
            time.sleep(2)
        
        return new_articles
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []

def save_articles_to_json(articles):
    """LÆ°u bÃ i viáº¿t vÃ o file JSON Ä‘á»ƒ import vÃ o Firebase"""
    output_file = os.path.join(os.path.dirname(__file__), 'articles_to_import.json')
    
    existing = []
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            existing = json.load(f)
    
    existing.extend(articles)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(existing, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ÄÃ£ lÆ°u {len(articles)} bÃ i vÃ o: {output_file}")
    return output_file

def main():
    print("=" * 50)
    print("ğŸš€ VietShare Article Crawler & AI Rewriter")
    print("=" * 50)
    
    config = load_config()
    processed = load_processed()
    
    if config['gemini_api_key'] == 'YOUR_GEMINI_API_KEY_HERE':
        print("\nâŒ Lá»—i: ChÆ°a cáº¥u hÃ¬nh Gemini API key!")
        print("ğŸ‘‰ Má»Ÿ file tools/config.json vÃ  thÃªm API key")
        print("ğŸ‘‰ Láº¥y key táº¡i: https://aistudio.google.com/app/apikey")
        return
    
    all_articles = []
    
    for source in config['sources']:
        articles = process_rss_feed(source, config, processed)
        all_articles.extend(articles)
    
    save_processed(processed)
    
    if all_articles:
        output_file = save_articles_to_json(all_articles)
        print(f"\nâœ… HoÃ n thÃ nh! ÄÃ£ crawl {len(all_articles)} bÃ i viáº¿t má»›i")
        print(f"ğŸ“ File output: {output_file}")
    else:
        print("\nğŸ“­ KhÃ´ng cÃ³ bÃ i viáº¿t má»›i Ä‘á»ƒ xá»­ lÃ½")

if __name__ == '__main__':
    main()
